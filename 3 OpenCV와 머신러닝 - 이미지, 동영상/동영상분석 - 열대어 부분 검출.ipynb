{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동영상 분석\n",
    "## 웹카메라의 이미지를 실시간으로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 웹카메라로부터 입력받기\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    #카메라로부터 이미지 읽기\n",
    "    _, frame = cap.read()\n",
    "    #이미지를 축소하기\n",
    "    frame = cv2.resize(frame, (500,300))\n",
    "    #윈도우에 이미지 출력하기\n",
    "    cv2.imshow('OpenCV Web Camera - press ENTER OR ESC -> EXIT', frame)\n",
    "    # ESC 또는 Enter키가 입력되면 반복 종료하기\n",
    "    k = cv2.waitKey(1) # 1m sec 대기\n",
    "    if k == 27 or k == 13: break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() # 윈도우 제거하기\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 카메라 이미지에서 붉은색 성분만 추출하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    frame 은 3차원 객체로 [:,:,0] 은 가장 처음 차원에 모든 요소를 선택후 두번째 차원의 모든 요소를 선택 \n",
    "    그리고 가장 마지막 차원의 첫번째 요소들만 적용\n",
    "    예제 > [[[1, 2, 3],[4, 5, 6],[7, 8, 9], ... [x, y, z] ]] -> 1, 4, 7 번 위치에 있는 요소(x위치)들만 0으로 적용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 웹카메라로부터 입력받기\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    #카메라로부터 이미지 읽기\n",
    "    _, frame = cap.read()\n",
    "    #이미지를 축소하기\n",
    "    frame = cv2.resize(frame, (500,300))\n",
    "    #파란색과 녹색 부분 제거하기\n",
    "    frame[:,:,0] = 0\n",
    "    frame[:,:,1] = 0\n",
    "    #윈도우에 이미지 출력하기\n",
    "    cv2.imshow('red Camera - press ENTER OR ESC -> EXIT', frame)\n",
    "    # ESC 또는 Enter키가 입력되면 반복 종료하기\n",
    "    k = cv2.waitKey(1) # 1m sec 대기\n",
    "    if k == 27 or k == 13: break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() # 윈도우 제거하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSV 색공간을 사용해 색 검출하기\n",
    "### 위의 방법은 붉은 부분이 추출된거 같지는않다. \n",
    "### HSV 방법은 색상(Hue), 채도(Saturation), 명도(Value Brightness)라는 3가지 값을 사용해 색을 표현하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 웹카메라로부터 입력받기\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    #카메라로부터 이미지 읽기\n",
    "    _, frame = cap.read()\n",
    "    #이미지를 축소하기\n",
    "    frame = cv2.resize(frame, (500,300))\n",
    "    #색공간을 HSV로 변환하기\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV_FULL)\n",
    "    # 색분할하기\n",
    "    h = hsv[:, :, 0]\n",
    "    s = hsv[:, :, 1]\n",
    "    v = hsv[:, :, 2]\n",
    "    # 붉은색을 가진 요소만 출력하기\n",
    "    img = np.zeros(h.shape, dtype=np.uint8)\n",
    "    img[((h < 50) | (h > 200)) & (s > 100)] = 255\n",
    "    \n",
    "    #윈도우에 이미지 출력하기\n",
    "    cv2.imshow('red Camera - press ENTER OR ESC -> EXIT', img)\n",
    "    # ESC 또는 Enter키가 입력되면 반복 종료하기\n",
    "    k = cv2.waitKey(1) # 1m sec 대기\n",
    "    if k == 27 or k == 13: break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() # 윈도우 제거하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 화면에 움직임이 있는 부분 추출하기 - cv2.absdiff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "감시카메라와 같은 용도로 화면에서 큰 움직임이 있을경우 저장하는 방법으로 사용할수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 웹카메라로부터 입력받기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "img_last = None     # 이전 프레임을 저장할 변수\n",
    "green = (0, 255, 0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    #카메라로부터 이미지 읽기\n",
    "    _, frame = cap.read()\n",
    "    #이미지를 축소하기\n",
    "    frame = cv2.resize(frame, (500,300))\n",
    "    #흑백 이미지로 변환하기\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (9,9), 0)\n",
    "    img_b = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "    #차이 확인하기\n",
    "    if img_last is None:\n",
    "        img_last = img_b\n",
    "        continue\n",
    "    frame_diff = cv2.absdiff(img_last, img_b)\n",
    "    cnts = cv2.findContours(frame_diff, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "    #차이가 있는 부분 출력하기\n",
    "    for pt in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(pt)\n",
    "        if w < 50: continue # 작은 변경 무시하기\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), green, 2)\n",
    "    #프레임 변수에 저장해두기\n",
    "    img_last = img_b\n",
    "    \n",
    "    #윈도우에 이미지 출력하기\n",
    "    cv2.imshow('Diff Camera - press ENTER OR ESC -> EXIT', frame)\n",
    "    cv2.imshow('Diff data', frame_diff)\n",
    "    cv2.imshow('Diff data2', img_b)\n",
    "    # ESC 또는 Enter키가 입력되면 반복 종료하기\n",
    "    k = cv2.waitKey(1) # 1m sec 대기\n",
    "    if k == 27 or k == 13: break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() # 윈도우 제거하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 파일 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#카메라 입력받기\n",
    "cap = cv2.VideoCapture(0)\n",
    "# 동영상 출력 전용 객체 생성하기\n",
    "fmt = cv2.VideoWriter_fourcc(\"m\", \"p\", \"4\", \"v\")\n",
    "fps = 30.0\n",
    "size = (1280, 640)\n",
    "writer = cv2.VideoWriter(\"test.m4v\", fmt, fps, size)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    # 이미지 축소하기\n",
    "    frame = cv2.resize(frame, size)\n",
    "    # 이미지 저장하기\n",
    "    writer.write(frame)\n",
    "    # 화면에도 출력하기\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    # Enter 키가 입력되면 반복 종료하기\n",
    "    if cv2.waitKey(1) ==13: break\n",
    "\n",
    "writer.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동영상에 움직이는 부분 캡쳐해서 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import cv2, os\n",
    "\n",
    "img_last = None # 이전 프레임을 저장할 변수\n",
    "no = 0 # 이미지 장수\n",
    "save_dir = \"./exfish\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "# 동영상 파일부터 입력받기\n",
    "cap = cv2.VideoCapture(\"fish.mp4\")\n",
    "\n",
    "while True:\n",
    "    # 이미지 추출하기\n",
    "    is_ok, frame = cap.read()\n",
    "    if not is_ok: break   # is_ok는 캡쳐한 비디오 프레임 없으면 False를 반환한다.\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    # 흑백 이미지로 변환하기\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "    img_b = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "    # 차이 확인하기\n",
    "    if not img_last is None:\n",
    "        frame_diff = cv2.absdiff(img_last, img_b)\n",
    "        cnts = cv2.findContours(frame_diff, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "        # 차이가 있는 부분 파일로 출력하기\n",
    "        for pt in cnts:\n",
    "            x,y,w,h = cv2.boundingRect(pt)\n",
    "            if w < 100 or w > 500: continue\n",
    "            # 추출 영역 저장\n",
    "            imgx = frame[y:y+h, x:x+w]\n",
    "            outfile = save_dir+\"/\"+str(no)+\".jpg\"\n",
    "            cv2.imwrite(outfile, imgx)\n",
    "            no += 1\n",
    "    img_last = img_b\n",
    "cap.release()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신 러닝으로 동영상에서 열대어가 많이 나오는 부분 찾기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 학습 크기와 경로 지정하기\n",
    "img_size = (64, 32)\n",
    "# path = os.path.dirname(os.path.abspath('3 OpenCV와 머신러닝 - 이미지, 동영상'))\n",
    "# path_fish = path + r'\\fish'\n",
    "# path_nofish = path + r'\\nofish'\n",
    "path_fish = './fish'\n",
    "path_nofish = './nofish'\n",
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터를 읽어 들이고 배열에 넣기\n",
    "def read_dir(path, label):\n",
    "    files = glob.glob(path+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        img = cv2.imread(f)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img_data = img.reshape(-1, ) # 1차원으로 변환하기\n",
    "        x.append(img_data)\n",
    "        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터 읽어들이기\n",
    "read_dir(path_nofish, 0)\n",
    "read_dir(path_fish, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 학습 전용과 테스트 전용으로 분리하기\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 학습하기\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "# 정답률 확인하기\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fish.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 저장하기\n",
    "joblib.dump(clf, 'fish.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  동영상 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os, copy\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 데이터 읽기\n",
    "clf = joblib.load(\"fish.pkl\")\n",
    "output_dir = \"./bestshot\"\n",
    "img_last = None\n",
    "fish_th = 3\n",
    "count = 0\n",
    "frame_count = 0\n",
    "if not os.path.isdir(output_dir): os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok 24 / 2790\n"
     ]
    }
   ],
   "source": [
    "# 동영상 파일 읽기\n",
    "cap = cv2.VideoCapture(\"fish.mp4\")\n",
    "while True:\n",
    "    # 이미지 추출하기\n",
    "    is_ok, frame = cap.read()\n",
    "    if not is_ok: break\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    frame2 = copy.copy(frame)\n",
    "    frame_count += 1\n",
    "    \n",
    "    # 이전 프레임과 비교를 위해 흑백으로 변환\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "    img_b = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "    if not img_last is None:\n",
    "        # 차이 추출하기\n",
    "        frame_diff = cv2.absdiff(img_last, img_b)\n",
    "        cnts = cv2.findContours(frame_diff, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "        # 차이가 있는 부분에 물고기가 있는지 확인하기\n",
    "        fish_count = 0\n",
    "        for pt in cnts:\n",
    "            x, y, w, h = cv2.boundingRect(pt)\n",
    "            if w< 100 or w > 500: continue # 노이즈 제거\n",
    "            # 추출 영역에 물고기가 있는지 확인하기\n",
    "            imgx = frame[y:y+w, x:x+h]\n",
    "            imagex = cv2.resize(imgx, (64, 32))\n",
    "            image_data = imagex.reshape(-1, )\n",
    "            pred_y = clf.predict([image_data])\n",
    "            if pred_y[0] == 1:\n",
    "                fish_count += 1\n",
    "                cv2.rectangle(frame2, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        # 물고기가 많이 있는지 확인하기 \n",
    "        if fish_count > fish_th:\n",
    "            fname = output_dir+\"/fish\"+str(count)+\".jpg\"\n",
    "            cv2.imwrite(fname, frame)\n",
    "            count += 1\n",
    "    cv2.imshow(\"FISH!\", frame2)\n",
    "    if cv2.waitKey(1) == 13: break\n",
    "    img_last = img_b\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"ok\", count, \"/\", frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
